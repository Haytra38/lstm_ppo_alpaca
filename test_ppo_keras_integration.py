#!/usr/bin/env python3
"""
Test d'int√©gration PPO avec LSTM (Keras)
V√©rifie que le mod√®le LSTM Keras peut √™tre utilis√© par l'environnement PPO
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Ajout du chemin du projet
sys.path.append('.')

from tensorflow.keras.models import load_model
from sklearn.preprocessing import RobustScaler, MinMaxScaler
import joblib

def load_keras_lstm_model(model_dir):
    """
    Charge un mod√®le LSTM Keras et son scaler
    """
    try:
        # Charger le mod√®le Keras
        model_path = os.path.join(model_dir, "model.keras")
        scaler_path = os.path.join(model_dir, "scaler.pkl")
        config_path = os.path.join(model_dir, "config.py")
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Mod√®le non trouv√©: {model_path}")
        
        # Charger le mod√®le
        model = load_model(model_path)
        print(f"‚úÖ Mod√®le Keras charg√©: {model_path}")
        
        # Charger le scaler
        if os.path.exists(scaler_path):
            scaler = joblib.load(scaler_path)
            print(f"‚úÖ Scaler charg√©: {scaler_path}")
        else:
            scaler = RobustScaler()  # Scaler par d√©faut
            print("‚ö†Ô∏è  Scaler non trouv√©, utilisation du scaler par d√©faut")
        
        # Charger la configuration si disponible
        config = {}
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r') as f:
                    config_content = f.read()
                # Extraire des informations de base
                if "sequence_length" in config_content:
                    import re
                    match = re.search(r'sequence_length\s*=\s*(\d+)', config_content)
                    if match:
                        config['sequence_length'] = int(match.group(1))
                print("‚úÖ Configuration charg√©e")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur lors du chargement de la config: {e}")
        
        return model, scaler, config
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
        return None, None, {}

def predict_with_keras_model(model, scaler, data, sequence_length=60, prediction_steps=5):
    """
    Effectue une pr√©diction avec le mod√®le Keras
    """
    try:
        if len(data) < sequence_length:
            raise ValueError(f"Pas assez de donn√©es: {len(data)} < {sequence_length}")
        
        # Prendre la derni√®re s√©quence
        sequence = data.tail(sequence_length)
        
        # Normaliser les donn√©es
        if hasattr(scaler, 'transform'):
            normalized_data = scaler.transform(sequence.values)
        else:
            normalized_data = sequence.values
        
        # Reshape pour le mod√®le LSTM (batch_size, timesteps, features)
        X = normalized_data.reshape(1, sequence_length, -1)
        
        # Pr√©diction
        prediction = model.predict(X, verbose=0)
        
        # D√©-normaliser si possible
        if hasattr(scaler, 'inverse_transform'):
            # Adapter la forme pour l'inverse transformation
            if prediction.shape[-1] < sequence.shape[1]:
                # Padding avec des z√©ros pour correspondre √† la forme originale
                padded_pred = np.zeros((prediction.shape[0], sequence.shape[1]))
                padded_pred[:, :prediction.shape[-1]] = prediction
                denormalized = scaler.inverse_transform(padded_pred)
                prediction = denormalized[:, :prediction.shape[-1]]
            else:
                prediction = scaler.inverse_transform(prediction)
        
        return prediction.flatten()
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la pr√©diction: {e}")
        return np.zeros(prediction_steps * data.shape[1])

def test_keras_lstm_integration():
    """
    Test l'int√©gration avec un mod√®le LSTM Keras existant
    """
    print("\U0001f9ea Test d'int√©gration PPO + LSTM (Keras)")
    print("=" * 55)
    
    # Chemins des mod√®les disponibles
    model_dirs = [
        "saved_models/robust",
        "saved_models/minmax", 
        "saved_models/test"
    ]
    
    for model_dir in model_dirs:
        if os.path.exists(model_dir):
            print(f"\nüìÅ Test du mod√®le: {model_dir}")
            
            # Charger le mod√®le
            model, scaler, config = load_keras_lstm_model(model_dir)
            
            if model is None:
                continue
            
            # Cr√©er des donn√©es de test
            print("\nüìä Cr√©ation de donn√©es de test...")
            dates = pd.date_range(start=datetime.now() - timedelta(days=2), end=datetime.now(), freq='1min')
            np.random.seed(42)
            
            # G√©n√©rer des donn√©es de prix r√©alistes
            initial_price = 150.0
            prices = [initial_price]
            
            for i in range(1, len(dates)):
                change = np.random.normal(0.0001, 0.01)
                new_price = prices[-1] * (1 + change)
                prices.append(new_price)
            
            test_df = pd.DataFrame({
                'Open': prices,
                'High': [p * (1 + abs(np.random.normal(0, 0.001))) for p in prices],
                'Low': [p * (1 - abs(np.random.normal(0, 0.001))) for p in prices],
                'Close': prices,
                'Volume': np.random.randint(1000, 10000, len(dates))
            }, index=dates)
            
            print(f"‚úÖ Donn√©es de test cr√©√©es: {len(test_df)} p√©riodes")
            
            # Test de pr√©diction
            print("\n\U0001f52e Test de pr√©diction...")
            
            sequence_length = config.get('sequence_length', 60)
            prediction = predict_with_keras_model(model, scaler, test_df, sequence_length)
            
            print(f"‚úÖ Pr√©diction r√©ussie!")
            print(f"   \U0001f4c8 Forme de la pr√©diction: {prediction.shape}")
            print(f"   \U0001f4ca Premi√®res valeurs: {prediction[:5]}")
            
            # Test avec l'environnement PPO
            print("\n\U0001f3d7Ô∏è  Test avec l'environnement PPO...")
            
            try:
                from train_minute_model_lstm import MinuteTradingEnvHistorical
                
                # Cr√©er l'environnement avec le mod√®le LSTM
                env = MinuteTradingEnvHistorical(
                    df=test_df,
                    initial_balance=1000.0,
                    lookback_periods=30,
                    lstm_model_path=model_dir,  # Passer le chemin du mod√®le
                    use_lstm_features=True
                )
                
                print("‚úÖ Environnement PPO cr√©√© avec succ√®s")
                print(f"   \U0001f4ca Taille d'observation: {env.observation_space.shape}")
                
                # Test rapide
                obs, info = env.reset()
                print(f"‚úÖ Reset r√©ussi, observation shape: {obs.shape}")
                
                # Faire quelques pas
                for step in range(min(5, len(test_df) - 30)):
                    action = 0  # Hold
                    obs, reward, done, truncated, info = env.step(action)
                    
                    if done or truncated:
                        break
                
                print(f"‚úÖ Test environnement: {step + 1} steps r√©ussis")
                
                # V√©rifier les features LSTM
                if hasattr(env, 'lstm_model') and env.lstm_model is not None:
                    print("‚úÖ Mod√®le LSTM charg√© dans l'environnement")
                else:
                    print("‚ö†Ô∏è  Mod√®le LSTM non charg√© dans l'environnement")
                
                print(f"\U0001f389 Test r√©ussi pour {model_dir}!")
                return True
                
            except Exception as e:
                print(f"‚ùå Erreur avec l'environnement PPO: {e}")
                import traceback
                traceback.print_exc()
                continue
    
    print("\n‚ùå Aucun mod√®le n'a pu √™tre test√© avec succ√®s")
    return False

def main():
    print("\U0001f680 D√©marrage des tests d'int√©gration PPO + LSTM (Keras)")
    print("=" * 70)
    
    success = test_keras_lstm_integration()
    
    if success:
        print("\n\U0001f3c6 Tests r√©ussis!")
        print("\n\U0001f680 L'int√©gration PPO + LSTM fonctionne avec les mod√®les Keras existants")
        print("\nPour lancer l'entra√Ænement PPO:")
        print("  python train_minute_model_lstm.py --lstm-model saved_models/robust")
    else:
        print("\n‚ùå Les tests ont √©chou√©")
        print("V√©rifiez les mod√®les et la configuration")

if __name__ == "__main__":
    main()